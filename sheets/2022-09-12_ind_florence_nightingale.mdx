# Week 1 – 99% Invisible on Florence Nightingale

<iframe
  src="https://embed.podcasts.apple.com/us/podcast/433-florence-nightingale-data-viz-pioneer/id394775318?i=1000519252452&amp;itsct=podcast_box_player&amp;itscg=30200&amp;ls=1&amp;theme=auto"
  height="175px"
  frameborder="0"
  sandbox="allow-forms allow-popups allow-same-origin allow-scripts allow-top-navigation-by-user-activation"
  allow="autoplay *; encrypted-media *; clipboard-write"
  style={{
    width: '100%',
    maxWidth: 660,
    overflow: 'hidden',
    borderRadius: 10,
    backgroundColor: 'transparent',
  }}
/>

One note this excellent episode touched on was how charts can misrepresent data & mislead viewers absurdly quickly (in under a second). This isn’t news to anyone spending time on e.g. Twitter: I regularly see graphs on Twitter that contradict what the poster is claiming, & it’s sometimes not clear if the misleading claim is intentional or not.

Excel cannot prevent you from entering falsified data or making a misleading visualization, just as Illustrator can’t save you from making bad designs or Google Docs can’t save you from bad writing. (Nor should they.) The world is drastically better with desktop publishing available for free, because people who’d never have had access in prior centuries (such as with crown-appointed, guild-run printing presses in the Renaissance) contribute essential material & creative works to the world. As these creative tools expand, they add entire new dimensions to creative possibilities for both amateurs & professionals. In 2022, we’re watching this revolution play out week-by-week with rapidly-improving AI image generation software, which opens the door to newly alarming possibilities.

As users of these tools, we have a moral obligation to use them not to mislead or lie. But it’s simultaneously necessary & unavoidable to give everyone tools—we all deserve to be able to use the best tooling people & companies can produce—& either through intentional malice or careless speed, mistakes will undoubtedly be made.

As tool creators, we take on a responsibility to mitigate harm our platforms can cause. I’ve seen Twitter annotate misleading graphics this year as part of their Birdwatch program [source](https://www.platformer.news/p/elon-keeps-losing), expanding Twitter’s own moderation efforts to allow reputable Twitter users to mark missing context or misleading claims. OpenAI’s DALL-E image creation tooling, meanwhile, lightly blurs faces to implicitly communicate the imagery’s artificial nature ([source](https://www.platformer.news/p/how-dall-e-could-power-a-creative)).

As Florence Nightingale said about [her diagram](https://upload.wikimedia.org/wikipedia/commons/1/17/Nightingale-mortality.jpg), “this is for the vulgar public.” Your chart will be misinterpreted by viewers who don’t read the axes, are unable to see the color differences, or scroll by faster than they can interpret. When we create visualizations of data, we should try to road-test our graphics on different audiences & try to make them as genuine & comprehensible as possible. We must simultaneously make peace with the fact that misleading charts will be created, shared, & believed—it’s the cost of the freedom to make & share anything.
