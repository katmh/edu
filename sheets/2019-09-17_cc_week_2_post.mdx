# CC – Week 2: Software – Notebook

Though computers are ostensibly “universal machines,” a computer with no inputs is just a useless device, not a universal one. These inputs give the computer something to compute and ways to communicate with users. I strongly believe we should 

On a modern phone (arguably the most used shape of a computer in the current era), those primarily include the touchscreen display and the cameras (in addition to the microphones, data/charging port, and a wide array of embedded sensors).

The original iPhone announcement barely mentioned the camera (singular!), and didn’t even have video recording. Most of the launch presentation focused on the Multi-Touch touchscreen display, and the improved experience of phone calls. Yet now Multi-Touch is seen as a basic capability of any phone display, and any phone maker who tried to sell a phone based on voice calling would be laughed out of the market. Instead, the camera is by far the most meaningful selling point—just look at last week’s iPhone 11 launch event, where the camera segment dominated. While the improvements to the internal chip are significant, we care far more about the ways we interact with devices. For many consumers, their phones are primarily cameras.

A similar shift is happening to computers, but toward their displays, not their cameras. A few decades ago, many computers didn’t even have displays included, but now laptops are the majority of non-mobile computer sales. Surpassing laptops, there is an increasingly-popular trend of selling a computer only as a touchscreen display[^1]—such as the iPad Pro, Microsoft Surface, & various other PCs—with an array of optional accessories for more precise input, such as an attachable keyboard and stylus.

[^1]: What an iPad is now was a science fiction dream beyond imagination a few decades ago, when computers the size of city blocks powered a fraction of the computational abilities of a modern smartwatch.

New forms of computational input are incredibly difficult to develop and fail quickly & often. Google Glass promised always-on augmented reality, but the widespread social reaction device made the project fail quickly after launch. (The promo video, over half a decade later, is still a computational promise we have not had fulfilled, though smartwatches are beginning to fill the void.) [Leap Motion](https://www.leapmotion.com) never took off, but the touchscreen strip in Apple’s MacBook Pro, the [Touch Bar](https://www.apple.com/macbook-pro/) gives some similar abilities and is in widespread use.

Meanwhile, the iPhone 11 contains a new chip featuring “Ultra Wideband technology for spatial awareness.” No one but nerds care right now, and the technology will either become an important one embedded in every portable device in the next decade or a footnote in the history of iPhone features.

It’s difficult to imagine the original use of technologies—as best proven, perhaps, by the now-famous anecdote about the invention of Post-It notes. Products and technologies which are commercial failures at launch can take new life later as a different idea. But sometimes, like the iPhone camera, significantly change the course of computer history.

We need to keep developing new forms of computational input. The ideal state of a “universal machine” is one with which interactions with feel utterly natural. Maybe [Neuralink](https://www.neuralink.com) isn’t ready yet, but in the meantime, our building and iteration on computational inputs is what computers need most. They’ll often—usually, even—fail. But time sorts out which small ideas become indispensable tools and standard expectations for new products, and eventually, make universal machines even more universal.
